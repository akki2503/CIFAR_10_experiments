{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "szz86ANTDUus",
    "outputId": "2462b440-3cc1-429b-a82f-7ab7279b52f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "\n",
    "%tensorflow_version 1.x\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as Net\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FSUR6npViYZh",
    "outputId": "1e002d08-3f52-4525-9269-adc0b83826ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/model_dirs/assets\n"
     ]
    }
   ],
   "source": [
    "# Load MobileNetV2 pretrained model trained in ImageNet Dataset\n",
    "\n",
    "mobilenet_v2 = tf.keras.applications.MobileNetV2(weights='imagenet')\n",
    "tf.saved_model.save(mobilenet_v2, '/content/model_dirs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLGR82gIjSbi"
   },
   "outputs": [],
   "source": [
    "# Preprocessing image for MobileNetV2 model\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img('/content/elephant.png', target_size=(224, 224))\n",
    "x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "fgxd4G57jas5",
    "outputId": "959b441b-f285-412c-fe36-2fa89bc74089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504013', 'Indian_elephant', 0.61320823), ('n01871265', 'tusker', 0.29030368), ('n02504458', 'African_elephant', 0.016726842)]\n"
     ]
    }
   ],
   "source": [
    "# Perform infernece using MobileNetV2 Model\n",
    "\n",
    "preds = mobilenet_v2.predict(x)\n",
    "print('Predicted:', tf.keras.applications.mobilenet_v2.decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqrE56y6je4O"
   },
   "outputs": [],
   "source": [
    "# Function to calculate inference time and FPS speed of the model\n",
    "\n",
    "import time\n",
    "def time_my_model(model, data):\n",
    "    times = []\n",
    "    for i in range(20):\n",
    "        start_time = time.time()\n",
    "        one_prediction = model.predict(data)\n",
    "        delta = (time.time() - start_time)\n",
    "        times.append(delta)\n",
    "    mean_delta = np.array(times).mean()\n",
    "    fps = 1 / mean_delta\n",
    "    print('average(sec):{:.2f},fps:{:.2f}'.format(mean_delta, fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "E_uZq59Djkay",
    "outputId": "9d621065-2eea-44d8-b8f7-79aab1bfeb41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average(sec):0.07,fps:14.41\n",
      "average(sec):0.07,fps:14.63\n",
      "average(sec):0.07,fps:14.84\n",
      "average(sec):0.07,fps:14.65\n",
      "average(sec):0.07,fps:14.66\n"
     ]
    }
   ],
   "source": [
    "# Performing inference on the same image to check consistency\n",
    "\n",
    "for i in range(5):\n",
    "  time_my_model(mobilenet_v2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "qAQ8PTsrjnft",
    "outputId": "ec649a35-d9ed-4027-a9b5-82e7c0802af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (0, 0, 0)\n",
      "INFO:tensorflow:Loaded TensorRT version: (0, 0, 0)\n",
      "INFO:tensorflow:Assets written to: /content/trt_m2_dirs/assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the tensorflow model to Tensor RT optimized model \n",
    "\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "conversion_params = conversion_params._replace(precision_mode='FP16')\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "        input_saved_model_dir='/content/model_dirs/',\n",
    "        conversion_params=conversion_params,\n",
    "    )\n",
    "converter.convert()\n",
    "converter.save(output_saved_model_dir='/content/trt_m2_dirs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "601Irgk-j1v3",
    "outputId": "c4c5ab93-1f52-4b34-ab3e-cb04cac7d615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': TensorSpec(shape=(None, 1000), dtype=tf.float32, name='predictions')}"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved converted model\n",
    "\n",
    "root = tf.saved_model.load('/content/trt_m2_dirs')\n",
    "concrete_func = root.signatures['serving_default']\n",
    "import numpy as np\n",
    "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "concrete_func.structured_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "pJxh6kuTkDuS",
    "outputId": "6fcfb897-351b-482e-de0c-39b22c9d266d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Indian elephant' 'tusker' 'African elephant' 'triceratops' 'web site']\n",
      "['Indian elephant' 'tusker' 'African elephant' 'triceratops' 'web site']\n",
      "['Indian elephant' 'tusker' 'African elephant' 'triceratops' 'web site']\n",
      "['Indian elephant' 'tusker' 'African elephant' 'triceratops' 'web site']\n",
      "['Indian elephant' 'tusker' 'African elephant' 'triceratops' 'web site']\n"
     ]
    }
   ],
   "source": [
    "# Perform inference using the optimized model on the same\n",
    "# image to check consistency\n",
    "\n",
    "for i in range(5):\n",
    "  labeling = concrete_func(tf.constant(x.astype('float32')))\n",
    "  activations = tf.nn.softmax(labeling['predictions'])\n",
    "  print(imagenet_labels[np.argsort(activations)[0,::-1][:5]+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w5TGpYSCkPOX"
   },
   "outputs": [],
   "source": [
    "# Funtion to determine the infernece time of \n",
    "# optimized trt model\n",
    "\n",
    "def time_trt_model():\n",
    "    image_input = tf.constant(x.astype('float32'))\n",
    "    times = []\n",
    "    for i in range(20):\n",
    "        start_time = time.time()\n",
    "        one_prediction = concrete_func(input_1=image_input)\n",
    "        delta = (time.time() - start_time)\n",
    "        times.append(delta)\n",
    "    mean_delta = np.array(times).mean()\n",
    "    fps = 1 / mean_delta\n",
    "    print('average(sec):{:.2f},fps:{:.2f}'.format(mean_delta, fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U19M55E7kg2a"
   },
   "outputs": [],
   "source": [
    "# Preprocessing the image for MobileNetv2 Model\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img('/content/elephant.png', target_size=(224, 224))\n",
    "x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "WiIoTWfskzno",
    "outputId": "6f045f48-4000-4890-8537-b33c85c3083b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average(sec):0.04,fps:25.30\n",
      "average(sec):0.04,fps:24.98\n",
      "average(sec):0.04,fps:25.51\n",
      "average(sec):0.04,fps:24.96\n",
      "average(sec):0.04,fps:25.03\n"
     ]
    }
   ],
   "source": [
    "# Performing inference on the same image to check consistency\n",
    "\n",
    "for i in range(5):\n",
    "  time_trt_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "8Si4bnHLlDg4",
    "outputId": "4e4031e5-888f-4ead-e92f-7d25e01185a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9M\t/content/model_dirs/saved_model.pb\n",
      "108K\t/content/model_dirs/variables/variables.data-00001-of-00002\n",
      "14M\t/content/model_dirs/variables/variables.data-00000-of-00001\n",
      "98M\t/content/model_dirs/variables/variables.data-00000-of-00002\n",
      "20K\t/content/model_dirs/variables/variables.index\n",
      "112M\t/content/model_dirs/variables\n",
      "4.0K\t/content/model_dirs/assets\n",
      "99M\t/content/model_dirs/model.pb\n",
      "99M\t/content/model_dirs/model\n",
      "312M\t/content/model_dirs\n"
     ]
    }
   ],
   "source": [
    "# Checking for original model size\n",
    "!du --all -h '/content/model_dirs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "HC2g4ouqlJ8T",
    "outputId": "383e7093-d1eb-4e86-fa81-04499b3edbc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31M\t/content/trt_m2_dirs/saved_model.pb\n",
      "14M\t/content/trt_m2_dirs/variables/variables.data-00000-of-00001\n",
      "20K\t/content/trt_m2_dirs/variables/variables.index\n",
      "14M\t/content/trt_m2_dirs/variables\n",
      "4.0K\t/content/trt_m2_dirs/assets\n",
      "45M\t/content/trt_m2_dirs\n"
     ]
    }
   ],
   "source": [
    "# Checking for optimized model size\n",
    "!du --all -h '/content/trt_m2_dirs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2eEyirelXLs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TensorRt_Optimization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
